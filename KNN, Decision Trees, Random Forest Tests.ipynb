{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc67d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import neural_network_methods as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ce4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, num_train):\n",
    "    \n",
    "    train = data[0:num_train]\n",
    "    test  = data[num_train:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fe9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_X(data):\n",
    "    \n",
    "    n = len(data)\n",
    "    num_features = 0\n",
    "    \n",
    "    for i in range(len(data[0])):\n",
    "        if(data[0][i] == \",\"):\n",
    "            num_features += 1\n",
    "    \n",
    "    X = np.zeros((n, num_features))\n",
    "    for i in range(n):\n",
    "        arr = data[i].split(\",\")\n",
    "        for j in range(num_features):\n",
    "            X[i][j] = arr[j]\n",
    "        \n",
    "    return X.T\n",
    "    \n",
    "\n",
    "def construct_Y(data):\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    Y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        Y[i] = data[i][-1]\n",
    "        \n",
    "    return Y\n",
    "\n",
    "def accuracy(pred, Y):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(Y)):\n",
    "        if(pred[i]-Y[i]==0):\n",
    "            count +=1\n",
    "    \n",
    "    accuracy = count/len(Y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a45a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total = np.loadtxt('diabetes_dataset_total.csv', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd13fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data_total, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6260c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt =  DecisionTreeClassifier(criterion = 'log_loss', max_depth = 100)\n",
    "rf =  RandomForestClassifier()\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0ab3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = construct_X(train).T\n",
    "Y_train = construct_Y(train)\n",
    "\n",
    "X_test = construct_X(test).T\n",
    "Y_test = construct_Y(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906093a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb05baf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6545454545454545 0.6382978723404256 0.6538461538461539\n",
      "1 0.6428571428571429 0.6666666666666667 0.6538461538461539\n",
      "2 0.6071428571428571 0.6666666666666666 0.6538461538461539\n",
      "3 0.5818181818181818 0.6808510638297872 0.6538461538461539\n",
      "4 0.5818181818181818 0.6938775510204083 0.6538461538461539\n",
      "5 0.6071428571428571 0.68 0.6538461538461539\n",
      "6 0.6296296296296297 0.7083333333333334 0.6538461538461539\n",
      "7 0.5714285714285714 0.6530612244897959 0.6538461538461539\n",
      "8 0.6296296296296297 0.6382978723404256 0.6538461538461539\n",
      "9 0.5660377358490566 0.6521739130434783 0.6538461538461539\n",
      "10 0.6296296296296297 0.6808510638297872 0.6538461538461539\n",
      "11 0.5862068965517241 0.6538461538461539 0.6538461538461539\n",
      "12 0.5818181818181818 0.7058823529411765 0.6538461538461539\n",
      "13 0.6206896551724138 0.723404255319149 0.6538461538461539\n",
      "14 0.6153846153846153 0.68 0.6538461538461539\n",
      "15 0.6415094339622641 0.6956521739130435 0.6538461538461539\n",
      "16 0.5614035087719299 0.7058823529411765 0.6538461538461539\n",
      "17 0.5818181818181818 0.7083333333333334 0.6538461538461539\n",
      "18 0.6071428571428571 0.7346938775510203 0.6538461538461539\n",
      "19 0.6037735849056604 0.7058823529411765 0.6538461538461539\n",
      "20 0.6071428571428571 0.7391304347826088 0.6538461538461539\n",
      "21 0.5555555555555556 0.68 0.6538461538461539\n",
      "22 0.5357142857142857 0.6956521739130435 0.6538461538461539\n",
      "23 0.5660377358490566 0.6666666666666666 0.6538461538461539\n",
      "24 0.5714285714285714 0.6808510638297872 0.6538461538461539\n",
      "25 0.5357142857142857 0.6666666666666667 0.6538461538461539\n",
      "26 0.6415094339622641 0.7083333333333334 0.6538461538461539\n",
      "27 0.5964912280701755 0.6938775510204083 0.6538461538461539\n",
      "28 0.5862068965517241 0.6666666666666666 0.6538461538461539\n",
      "29 0.5925925925925926 0.6530612244897959 0.6538461538461539\n",
      "30 0.6181818181818182 0.6382978723404256 0.6538461538461539\n",
      "31 0.5614035087719299 0.7083333333333334 0.6538461538461539\n",
      "32 0.5357142857142857 0.6923076923076923 0.6538461538461539\n",
      "33 0.6428571428571429 0.68 0.6538461538461539\n",
      "34 0.5660377358490566 0.7083333333333334 0.6538461538461539\n",
      "35 0.5660377358490566 0.7083333333333334 0.6538461538461539\n",
      "36 0.5925925925925926 0.6938775510204083 0.6538461538461539\n",
      "37 0.6181818181818182 0.72 0.6538461538461539\n",
      "38 0.5660377358490566 0.6938775510204083 0.6538461538461539\n",
      "39 0.6071428571428571 0.6808510638297872 0.6538461538461539\n",
      "40 0.6296296296296297 0.7083333333333334 0.6538461538461539\n",
      "41 0.6415094339622641 0.7058823529411765 0.6538461538461539\n",
      "42 0.6037735849056604 0.72 0.6538461538461539\n",
      "43 0.6296296296296297 0.6086956521739131 0.6538461538461539\n",
      "44 0.6071428571428571 0.6938775510204083 0.6538461538461539\n",
      "45 0.6037735849056604 0.68 0.6538461538461539\n",
      "46 0.5925925925925926 0.6956521739130435 0.6538461538461539\n",
      "47 0.5862068965517241 0.6530612244897959 0.6538461538461539\n",
      "48 0.6071428571428571 0.68 0.6538461538461539\n",
      "49 0.5818181818181818 0.7659574468085106 0.6538461538461539\n",
      "50 0.5925925925925926 0.6956521739130435 0.6538461538461539\n",
      "51 0.6296296296296297 0.75 0.6538461538461539\n",
      "52 0.576923076923077 0.68 0.6538461538461539\n",
      "53 0.5818181818181818 0.68 0.6538461538461539\n",
      "54 0.5925925925925926 0.68 0.6538461538461539\n",
      "55 0.5818181818181818 0.6666666666666666 0.6538461538461539\n",
      "56 0.5925925925925926 0.723404255319149 0.6538461538461539\n",
      "57 0.6037735849056604 0.72 0.6538461538461539\n",
      "58 0.5862068965517241 0.7346938775510203 0.6538461538461539\n",
      "59 0.6296296296296297 0.68 0.6538461538461539\n",
      "60 0.5964912280701755 0.6521739130434783 0.6538461538461539\n",
      "61 0.5283018867924528 0.6530612244897959 0.6538461538461539\n",
      "62 0.6181818181818182 0.6938775510204083 0.6538461538461539\n",
      "63 0.6071428571428571 0.72 0.6538461538461539\n",
      "64 0.6153846153846153 0.6938775510204083 0.6538461538461539\n",
      "65 0.5818181818181818 0.6938775510204083 0.6538461538461539\n",
      "66 0.5818181818181818 0.68 0.6538461538461539\n",
      "67 0.6296296296296297 0.7346938775510203 0.6538461538461539\n",
      "68 0.5925925925925926 0.7346938775510203 0.6538461538461539\n",
      "69 0.5454545454545454 0.6938775510204083 0.6538461538461539\n",
      "70 0.5283018867924528 0.6938775510204083 0.6538461538461539\n",
      "71 0.6071428571428571 0.72 0.6538461538461539\n",
      "72 0.6181818181818182 0.723404255319149 0.6538461538461539\n",
      "73 0.5964912280701755 0.7391304347826088 0.6538461538461539\n",
      "74 0.5818181818181818 0.6521739130434783 0.6538461538461539\n",
      "75 0.5925925925925926 0.723404255319149 0.6538461538461539\n",
      "76 0.6037735849056604 0.75 0.6538461538461539\n",
      "77 0.5454545454545454 0.6938775510204083 0.6538461538461539\n",
      "78 0.6181818181818182 0.6808510638297872 0.6538461538461539\n",
      "79 0.6181818181818182 0.72 0.6538461538461539\n",
      "80 0.5714285714285714 0.6938775510204083 0.6538461538461539\n",
      "81 0.5925925925925926 0.6938775510204083 0.6538461538461539\n",
      "82 0.5660377358490566 0.6530612244897959 0.6538461538461539\n",
      "83 0.5357142857142857 0.7083333333333334 0.6538461538461539\n",
      "84 0.6428571428571429 0.68 0.6538461538461539\n",
      "85 0.6181818181818182 0.72 0.6538461538461539\n",
      "86 0.5925925925925926 0.6666666666666666 0.6538461538461539\n",
      "87 0.5818181818181818 0.7058823529411765 0.6538461538461539\n",
      "88 0.6071428571428571 0.6938775510204083 0.6538461538461539\n",
      "89 0.6428571428571429 0.7346938775510203 0.6538461538461539\n",
      "90 0.5454545454545454 0.6808510638297872 0.6538461538461539\n",
      "91 0.6037735849056604 0.68 0.6538461538461539\n",
      "92 0.6296296296296297 0.7346938775510203 0.6538461538461539\n",
      "93 0.5454545454545454 0.6938775510204083 0.6538461538461539\n",
      "94 0.5925925925925926 0.6938775510204083 0.6538461538461539\n",
      "95 0.5555555555555556 0.6938775510204083 0.6538461538461539\n",
      "96 0.5925925925925926 0.6938775510204083 0.6538461538461539\n",
      "97 0.5818181818181818 0.6382978723404256 0.6538461538461539\n",
      "98 0.5614035087719299 0.6666666666666667 0.6538461538461539\n",
      "99 0.5964912280701755 0.6666666666666666 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "\n",
    "accuracy_array_dt  = np.zeros(iterations)\n",
    "accuracy_array_rf  = np.zeros(iterations)\n",
    "accuracy_array_knn = np.zeros(iterations)\n",
    "\n",
    "f1_array_dt  = np.zeros(iterations)\n",
    "f1_array_rf  = np.zeros(iterations)\n",
    "f1_array_knn = np.zeros(iterations)\n",
    "\n",
    "precision_array_dt  = np.zeros(iterations)\n",
    "precision_array_rf  = np.zeros(iterations)\n",
    "precision_array_knn = np.zeros(iterations)\n",
    "\n",
    "recall_array_dt  = np.zeros(iterations)\n",
    "recall_array_rf  = np.zeros(iterations)\n",
    "recall_array_knn = np.zeros(iterations)\n",
    "\n",
    "for i in range(iterations):\n",
    "    X_train = construct_X(train).T\n",
    "    Y_train = construct_Y(train)\n",
    "\n",
    "    X_test = construct_X(test).T\n",
    "    Y_test = construct_Y(test)\n",
    "    \n",
    "    dt = dt.fit(X_train, Y_train)\n",
    "    Y_predict_dt = dt.predict(X_test)\n",
    "    \n",
    "    rf = rf.fit(X_train, Y_train)\n",
    "    Y_predict_rf = rf.predict(X_test)\n",
    "    \n",
    "    knn = knn.fit(X_train, Y_train)\n",
    "    Y_predict_knn = knn.predict(X_test)\n",
    "    \n",
    "    accuracy_array_dt[i]  = accuracy(Y_predict_dt, Y_test)\n",
    "    accuracy_array_rf[i]  = accuracy(Y_predict_rf, Y_test)\n",
    "    accuracy_array_knn[i] = accuracy(Y_predict_knn, Y_test)\n",
    "    \n",
    "    f1_array_dt[i]  = f1_score(Y_predict_dt, Y_test)\n",
    "    f1_array_rf[i]  = f1_score(Y_predict_rf, Y_test)\n",
    "    f1_array_knn[i] = f1_score(Y_predict_knn, Y_test)\n",
    "    \n",
    "    precision_array_dt[i]  = precision_score(Y_predict_dt, Y_test)\n",
    "    precision_array_rf[i]  = precision_score(Y_predict_rf, Y_test)\n",
    "    precision_array_knn[i] = precision_score(Y_predict_knn, Y_test)\n",
    "    \n",
    "    recall_array_dt[i]  = recall_score(Y_predict_dt, Y_test)\n",
    "    recall_array_rf[i]  = recall_score(Y_predict_rf, Y_test)\n",
    "    recall_array_knn[i] = recall_score(Y_predict_knn, Y_test)\n",
    "    \n",
    "    print(i, f1_array_dt[i], f1_array_rf[i], f1_array_knn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4d652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max F1 score for decision trees: 0.6545454545454545\n",
      "Max F1 score for random forest: 0.7659574468085106\n",
      "Max F1 score for K-nearest neighbors: 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "print('Max F1 score for decision trees:',np.max(f1_array_dt))\n",
    "print('Max F1 score for random forest:',np.max(f1_array_rf))\n",
    "print('Max F1 score for K-nearest neighbors:',np.max(f1_array_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa61ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
